= Web Developers Baseline
:toc:
:toc-title: Зміст:
:sectnums:

== Вступ

Цей документ описує мінімальний набір загальних знань для розробника (від рівня junior і вище). Це список того, що дається в університеті й що може стати в пригоді на роботі, допоможе у проєктуванні, допоможе у налагодженні веб-застосунків, допоможе у співбесідах.

Матеріал складається з розділів. Кожен розділ покриває якийсь базовий аспект розробки і складається з двох підрозділів.

* Поняття, якими потрібно володіти
* Практичні завдання для виконання

Щодо кожного поняття важливо наступне:

. Вміти розповісти що це
. Вміти розповісти навіщо конкретна сутність існує. Навіщо вона потрібна.

Для роботи необхідно створити git-репозиторій. Для кожного завдання потрібно створити директорію та по виконанню практичного завдання коммітити артефакти (це може бути текстовий документ, код, скріншоти). Головне завдання, щоб можна було перевірити, як усі завдання були виконані. Для випадків, коли потрібно переглянути відео або прочитати статтю, то зробити файлик з резюме контенту на 1-5 речень (ключові ідеї).

*Важливо:* якщо щось не виходить, сміливо просити по допомогу в студентів, викладачів. Так, завдання потрібно зробити самому, але гуглити, просити по допомогу і робити все, що  допоможе краще розібратися в темі за меншу кількість часу. Сміливо показувати проміжні результати викладачу, команді, друзям тощо.

== Вміння налагодити запит від клієнта до серверу

=== Поняття, якими потрібно володіти

. IP address, netmask
. Default gateway
. DNS Server
. DNS record types (A, AAAA, MX)
. DHCP
. TCP vs UDP
. HTTP використовує TCP або UDP?
. DNS використовує TCP або UDP?
. TCP socket
. NAT
. ICMP

=== Практичні завдання для виконання

. З консолі переглянути поточні мережеві налаштування
.. ip-address комп'ютера
.. DNS сервер, який використовується
.. Default gateway
. Подивитися чи доступний сервер
.. За допомогою утиліти dig подивитися, куди вказує A запис DNS сервера для домену google.com
.. За допомогою утиліти dig подивитися подивитися, куди вказує AAAA запис DNS сервера для домену google.com
.. Пропінгувати сервер по ipv4, ipv6
.. Просканувати відкриті порти на сервері за допомогою утиліти nmap
. Перевірити доступність веб-сайту
.. Спробувати запросити сторінку http://google.com[google.com] за допомогою curl
.. За допомогою curl подивитися куди вказує http редирект під час заходу на http://google.com[google.com]

*Швидкість світла та Веб*

Майже завжди, під час розмови про продуктивність веб-сайту, ми говоримо про час очікування користувачем якоїсь події («First contentful paint» («Largest contentful paint» і тд). Ми часто обговорюємо оптимізації фронтенда і бекенда. І це круто, але залишається корінь усіх бід - швидкість світла. Часто JavaScript розробники випускають цю проблему з уваги.

Припустимо наступне:

. Неахай бекенд рендерить сторінку (або формує JSON) за 20мс.
. Не існує ніякого WiFi, провайдерів, маршрутизації і тд. Є просто оптоволоконний кабель, який одним кінцем вставлений у ноутбук юзера, а другим безпосередньо в сервер у Сан-Франциско (SF). Відстань по прямій від Києва (K)) до Сан-Франциско (SF) - 9,848 км (візьмемо 10 тис км. для простоти рахунку).
. Швидкість світла у вакуумі 300 тис. км/сек, швидкість світла в оптоволокні буде нижчою - 200 тис. км/сек.


Якщо ми порахуємо час, який проведе наш запит у дорозі, то ми отримаємо: 2 * (10 тис км. / 200 тис. км/сек.) =  =0.1сек або 100 мс. Множення на 2 відбувається через те, що ми враховуємо шлях в обидві сторони: від клієнта до сервера і назад від сервера до клієнта.

. Запит спочатку йде від вашого комп'ютера (клієнта) до сервера — це перша половина шляху.
. Потім сервер надсилає відповідь назад до клієнта — це друга половина шляху.

Таким чином, загальний час дорівнює часу, який потрібен для проходження запиту туди й назад (round-trip time, RTT). Швидше отримати відповідь не дозволить швидкість світла. Додаємо час опрацювання запиту і ми отримаємо 120 мс - у 6 разів довше, ніж наш запит обробляє наш бекенд.

|===
|*Запит до бекенда*
|50ms: Kyiv -------запит-----> SF
|20ms: робота бекенда
|50ms: Kyiv <------відповідь------- SF
|===

Добре, ми вже з'ясували, що ніколи не пограємо в CS:GO з хлопцями з Сан-Франциско з пінгом нижче 100 мс. Давайте далі :)

Перед тим як запросити дані з сервера ми маємо встановити мережеве з'єднання. Протокол HTTP працює поверх TCP, отже нам потрібне TCP-з'єднання із сервером.

Для встановлення TCP з'єднання використовується так зване «потрійне рукостискання» («TCP 3-way handshake») і тепер наш запит має такий вигляд:

|===
|*TCP з'єднання*
|50ms: Kyiv -------syn--------> SF
|50ms: Kyiv <------syn/ack----- SF
|50ms: Kyiv -------ack--------> SF
|*Запит до бекенда*
|Kyiv -------запит-----> SF
|20ms: робота бекенда
|50ms: Kyiv <------відповідь------- SF
|===

Ми не витрачаємо додаткові 50ms після TCP хендшейка, оскільки ми можемо одразу почати надсилати запит після надсилання ack, нам не потрібно чекати на відповідь від сервера. Сервер, як прийме ack, вважатиме з'єднання відкритим і одразу почне обробляти наш запит.

Тобто відповідь користувач отримає через 220ms, в 11 разів довше, ніж відпрацьовував наш бекенд.

Але ми використовуємо HTTPS і нам потрібне SSL/TLS-з'єднання, і воно встановлюється поверх TCP, і в нього є свій механізм рукостискання для обміну ключами шифрування, і це потрібно зробити до того моменту, як ми надішлемо наш запит на сервер.

 Наша схема перетворюється на:

|===
| *TCP з'єднання*
| 50ms: Kyiv -------syn--------> SF
| 50ms: Kyiv <------syn/ack----- SF
| 50ms: Kyiv -------ack--------> SF
| *TLS з'єднання*
| Kyiv ---представлення--> SF
| 50ms: Kyiv <--сертифікати----- SF
| 50ms: Kyiv ---обмін ключами--> SF
| 50ms: Kyiv <--обмін ключами--- SF
| *Запит до бекенда*
| 50ms: Kyiv -------запит-----> SF
| 20ms: робота бекенда
| 50ms: Kyiv <------відповідь------- SF
|===

Тобто в умовах, які не можуть навіть існувати, коли користувач має оптоволоконний кабель завдовжки в 10 тисяч км від свого ноутбука до сервера, він отримає відповідь за 420 мс, що в 21 раз довше, ніж відпрацьовує наш бекенд. Це без урахування того, що нам потрібно ще спочатку збігати до DNS, щоб отримати ip-адресу сервера.

Якщо ми розробляємо веб-застосунки (не важливо фронтенд або бекенд), то зобов'язані розуміти ази роботи вебу.

Ми вже розібралися, що є швидкість світла і вона впливає на затримки під час передачі даних. У нас є затримки на TCP і TLS рукостискання, також є час на шляху запиту і відповіді. Чи можемо ми говорити, що це максимальні затримки, які ми отримуємо?

Насправді все складніше, і навіть за найвищої пропускної спроможності мережі в нас будуть додаткові затримки в передаванні даних.

Є 2 нюанси, які важливі:

. TCP контролює доставлення пакетів і для того, щоб зрозуміти, що пакети було доставлено, потрібне якесь підтвердження від одержувача. Для цього у відповідь надсилається пакет із прапором «ack» (acknowledge).
.. Клієнт і сервер від самого початку не знають доступної на цей час пропускної здатності мережі. Вона залежить від можливостей сервера, від можливостей проміжних вузлів, від активності інших вузлів у цій же мережі тощо. Єдиний спосіб дізнатися - це пробувати передавати дані з різною швидкістю і дивитися, чи доходять вони (чекати підтвердження, що друга сторона отримала їх).

Як це працює?

Коли ми робимо запит до сервера, він спочатку надсилає нам частину даних, потім чекає на підтвердження, потім збільшує обсяг даних, що передаються, вдвічі і знову чекає на відповідь. Якщо все ок, ще раз збільшує і так далі до моменту, поки він не досягне максимального обсягу даних, які готовий приймати клієнт.

Як це все називається?

* Механізм поступового збільшення швидкості передачі даних називається «TCP Slow Start»

* Ліміт відправника на обсяг даних у дорозі називається «Congestion window size» (CWND). Після відправлення цього обсягу даних, відправник повинен чекати підтвердження про те, що дані дійшли. Збільшення цього ліміту і є «TCP Slow Start». ВАЖЛИВО: про цей ліміт знає тільки відправник і він сам для себе його регулює. CWND вимірюється в «сегментах» (сегмент зазвичай не більше 1,46KB). Стартове значення за стандартом - 10 сегментів (14.6KB)

* Також є обмеження одержувача на обсяг даних, який він може прийняти - «Receiver window size» (RWND). Одержувач надсилає відправнику RWND у кожному пакеті з підтвердженням (з прапором ack). Оскільки передача динних відбувається в обидві сторони, то кожна сторона може виступати як одержувачем, так і відправником. Одержувач може передати RWND, що дорівнює нулю, це свідчить про те, що відправник повинен призупинити передачу.

Обидві змінні обмежують кількість даних, яку можна відправити, це завжди мінімум із CWND і RWND.

Тепер давайте намалюємо, що насправді відбувається, коли браузер хоче завантажити наш JavaScript файл на 50KB.
Візьмемо ті самі локації - Київ (K) і Сан-Франциско (SF).

|===
| *TCP з'єднання*
| 50ms: Kyiv -------syn--------> SF
| 50ms: Kyiv <------syn/ack----- SF
| 50ms: Kyiv -------ack--------> SF
| *TLS з'єднання*
| Kyiv ---представлення--> SF
| 50ms: Kyiv <--сертифікати----- SF
| 50ms: Kyiv ---обмін ключами--> SF
| 50ms: Kyiv <--обмін ключами--- SF
|*HTTP запит до сервера*
| 50ms: Kyiv -------запит-----> SF
| 20ms: робота бекенда
| 50ms: Kyiv <-----14.6KB------- SF
| 50ms: Kyiv -------ack--------> SF
| 50ms: Kyiv <-----29.2KB------- SF
| 50ms: Київ -------ack--------> SF
| 50ms: Київ <-----6.2KB-------- SF
|===

Швидкість у 100 Мбіт/с говорить про те, що ми отримаємо 50KB через 4ms, але насправді у нас це займе 620ms.
Найцікавіше, що якби наш JS файл був би 40KB, то ми отримали б його на 100 мс раніше.

Нам може здаватися, що трохи більший розмір даних не впливає ні на що, якщо у користувачів швидкий інтернет, але ми бачимо, що це не так.

Тому слід використовувати Gzip компресію c HTTP, слідкувати за Cookie (вони можуть бути великими), стискати картинки і видаляти з них метадані. Звичайно, не забувати про CDN (може дати істотний виграш).

Далі я спробую описати детальніше, що в нас є, щоб зробити наші веб-застосунки швидшими.

Але є ще одна проблема, про яку все-таки варто сказати - «Head-of-line Blocking». Насправді коли говорять про «Head-of-Line Blocking», то можуть мати на увазі різне.

Є 2 варіанти цієї проблеми:

*«Head-of-line Blocking» на рівні TCP*

Ми розглянули ситуацію, коли у нас немає втрат пакетів, але на практиці пакети завжди губляться. Більш того, TCP Slow Start збільшує швидкість поки не почнуть губитися пакети, потім значно зменшує швидкість і починає підіймати повільніше.

Втрати пакетів можуть призводити до «Head-of-line Blocking» на TCP рівні.

Спробуємо описати основну ідею.

TCP відповідає за те, щоб пакети прийшли в додаток у правильному порядку.
Якщо сервер відправив: [1][2][3][4][5], а отримали ми (або в іншому порядку) [2][3][4][5].

То ці пакети перебувають у TCP буфері одержувача, поки сервер відправляє нам повторно пакет [1]. Тобто, завдання TCP-протоколу вибудувати пакети в правильну чергу перед тим, як вони потраплять у додаток. Це зручно, але далеко не завжди потрібно.

*«Head-of-line Blocking» на рівні HTTP/1.x*

Тут трохи інша ситуація.

Припустимо, нам потрібно зробити 10 HTTP-запитів. Браузер надсилає запити один за одним і виходить, щоб надіслати новий, він має дочекатися результату попереднього.

Схематично це виглядає так:

|===
| 50ms: Kyiv ------запит 1----> SF
| 20ms: робота бекенда (запит 1)
| 50ms: Kyiv <-----відповідь 1------ SF
| 50ms: Kyiv ------запит 2----> SF
| 20ms: робота бекенда (запит 2)
| 50ms: Kyiv <-----відповідь 2------ SF
| 50ms: Kyiv ------запит 3----> SF
| 20ms: робота бекенда (запит 3)
| 50ms: Kyiv <-----відповідь 3------ SF
|===

Для спрощення я проґавив усі моменти, пов'язані зі встановленням з'єднання (TCP-handshake, TLS-handshake, TCP Slow Start).

У зв'язку з цим, у HTTP/1.1 з'явився «HTTP Pipelining». Суть - відправити одразу пачку запитів і чекати відповіді.
«HTTP Pipelining» має такий вигляд:

|===
| 50ms: Kyiv ------запит 1----> SF
| Kyiv ------запит 2----> SF
| Kyiv ------запит 3----> SF
| 20ms: робота бекенда (запит 1)
| робота бекенда (запит 2)
| робота бекенда (запит 3)
| 50ms: Kyiv <-----відповідь 1------ SF
| Kyiv <-----відповідь 2------ SF
| Kyiv <-----відповідь 3------ SF
|===

Це корисна штука (120мс проти 360мс), але на практиці вона відключена в більшості браузерів через те, що реалізації серверів часто містять баги. Але навіть якби це працювало, все одно ми маємо проблему «Head of line blocking»: якщо обробка першого запиту триватиме 1 секунду, то відповіді не зможуть повернутися раніше ніж за секунду (оскільки перший запит блокує повернення інших).

Так, браузер може паралельно відкривати 4-6 з'єднань (це з налаштуваннями за замовчуванням), але це лише частково рятує ситуацію.

Проблеми з DNS.

* У 99% випадків для DNS використовується UDP (за рідкісними винятками, коли відповідь не влазить у датаграму, тоді може бути ініційоване TCP-з'єднання). Тобто нам майже ніколи не потрібна установка з'єднання, що сильно зменшує нашу проблему. Питання безпеки поки що опустимо.

* Найімовірніше, ми звертаємося до DNS сервера провайдера і сервер цей розташований досить близько. Так, це все одно окремий запит, який теж впливає на те, як швидко користувач побачить сторінку, але в деталі поки що вдаватися не будемо.
